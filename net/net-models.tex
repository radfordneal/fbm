\documentclass{report}[11pt]

\topmargin -0.5in
\textheight 9in
\oddsidemargin -0.15in
\evensidemargin -0.15in
\textwidth 6.8in

\tolerance=1600 %allow some tolerance in extending after line.
\parskip=6pt
\overfullrule=0pt %no dark lines if overfull

\setlength{\parindent}{0pt}
\setlength{\partopsep}{0pt}
\setlength{\topsep}{0pt}

\renewcommand{\topfraction}{0.8}
\renewcommand{\textfraction}{0.1}

\setcounter{bottomnumber}{1}
\renewcommand{\bottomfraction}{0.8}

\def\beq{\begin{eqnarray}}
\def\eeq{\end{eqnarray}}
\def\eep{\end{eqnarray}}

\begin{document}

\subsection*{Neural Network Models Implemented in the Flexible
   Bayesian Modelling Software}

Radford M. Neal, 2022

This document gives the mathematical details of the Bayesian neural
network models implemented in the FBM software.  The notation used is
summarized on the next page.

\begin{table}[p]
\begin{center}\small
\begin{tabular}{ll}
%
  \multicolumn{2}{c}{\bf Values associated with units} \\[5pt]
%
  $v^I_i$            & Value of $i$th input unit, before the offset is 
                       added \\[3pt]
  $v^{\ell}_i$       & Value of $i$th hidden unit in layer $\ell$, before the  
                       offset is added \\[3pt]
  $v^O_i$            & Value of the $i$th output unit \\[10pt]

  $u^{\ell}_i$       & Value of the input to the $i$th unit of hidden
                       layer $\ell$ \\[3pt]
  $a^{\ell}$         & Activation function for hidden layer $\ell$, used
                       to compute $v^{\ell}_i = a^{\ell}(u^{\ell}_i)$\\[11pt]
%
  \multicolumn{2}{c}{\bf Parameters of the network} \\[5pt]
%
  $t^I_i$            & Offset for $i$th input unit \\[3pt]
  $t^\ell_i$         & Offset for $i$th hidden unit in layer $\ell$ \\[3pt]

  $b^{\ell}_j$       & Bias for $j$th unit in hidden layer $\ell$ \\[3pt]
  $b^O_j$            & Bias for $j$th output unit \\[10pt]

  $w^{I,O}_{i,j}$    & Weight from $i$th input unit to $j$th output unit \\[3pt]
  $w^{I,\ell}_{i,j}$ & Weight from $i$th input unit to $j$th unit in hidden
                       layer $\ell$ \\[3pt]
  $w^{\ell\!-\!1,\ell}_{i,j}$ & Weight from $i$th unit in hidden layer
                       $\ell\!-\!1$ to $j$th unit in hidden layer $\ell$ \\[3pt]
  $w^{\ell,O}_{i,j}$   & Weight from $i$th unit in hidden layer $\ell$ to the
                       $j$th output unit \\[10pt]

  $b^{\ell}_k$       & Bias $k$ in configured biases for hidden 
                       layer $\ell$ \\[3pt]
  $b^O_k$            & Bias $k$ in configured biases for the output 
                       layer \\[3pt]
  $w^{I,\ell}_k$     & Weight $k$ in configured connections from the input layer
                       to hidden layer $\ell$ \\[3pt]
  $w^{I,O}_k$        & Weight $k$ in configured connections from the input layer
                       to the output layer $\ell$ \\[3pt]
  $w^{\ell\!-\!1,\ell}_k$ & Weight $k$ in configured connections from hidden 
                        layer $\ell\!-\!1$ to hidden layer $\ell$ \\[3pt]
  $w^{\ell,O}_k$     & Weight $k$ in configured connections from last hidden 
                        layer, $\ell$, to the output layer \\[3pt]
  $B^{\ell}$         & Set of doublets, $(j,k)$, giving configuration of
                       biases for hidden layer $\ell$ \\[3pt]
  $B^{O}$            & Set of doublets, $(j,k)$, giving configuration of
                       biases for the output layer \\[3pt]
  $C^{I,\ell}$       & Set of triplets, $(i,j,k)$, giving configuration of
                       connections from the input layer to hidden 
                       layer $\ell$ \\[3pt]
  $C^{I,O}$          & Set of triplets, $(i,j,k)$, giving configuration of
                       connections from the input layer to the output 
                       layer \\[3pt]
  $C^{\ell\!-\!1,\ell}$  & Set of triplets, $(i,j,k)$, giving configuration of
                       connections from hidden layer $\ell\!-\!1$ to hidden 
                       layer $\ell$\\[3pt]
  $C^{\ell,O}$       & Set of triplets, $(i,j,k)$, giving configuration of
                       connections from the last hidden layer, $\ell$, to the
                       output layer \\[11pt]
%
  \multicolumn{2}{c}{\bf Hyperparameters defining priors for parameters} \\[5pt]
%
  $\sigma^I_t$        & Common sigma for offsets of input units \\[3pt]
  $\sigma^{\ell}_t$   & Common sigma for offsets of units in hidden layer 
                      $\ell$ \\[10pt]

  $\sigma^{\ell}_b$   & Common sigma for biases of units in hidden layer 
                      $\ell$ \\[3pt]
  $\sigma^O_b$        & Common sigma for biases of output units \\[10pt]

  $\sigma^{I,O}_w$    & Common sigma for weights from input units to output
                        units \\[3pt]
  $\sigma^{I,\ell}_w$ & Common sigma for weights from input units to units
                        in hidden layer $\ell$ \\[3pt]
  $\sigma^{\ell\!-\!1,\ell}_w$ & Common sigma for weights from units in hidden
                             layer $\ell\!-\!1$ to units in hidden layer $\ell$ 
                             \\[3pt]
  $\sigma^{\ell,O}_w$    & Common sigma for weights from units in hidden
                           layer $\ell$ to output units \\[10pt]

  $\sigma^{I,O}_{w,i}$    & Sigma for weights from input unit $i$ to output
                            units \\[3pt]
  $\sigma^{I,\ell}_{w,i}$ & Sigma for weights from input unit $i$ to units
                            in hidden layer $\ell$ \\[3pt]
  $\sigma^{\ell\!-\!1,\ell}_{w,i}$ & Sigma for weights from unit $i$ in hidden
                             layer $\ell\!-\!1$ to units in hidden layer $\ell$ 
                                 \\[3pt]
  $\sigma^{\ell,O}_{w,i}$  & Sigma for weights from unit $i$ in hidden layer
                             $\ell$ to output units \\[10pt]

  $\sigma^O_{a,j}$      & Sigma adjustment for weights and biases into output 
                          unit $j$ \\[3pt]
  $\sigma^{\ell}_{a,j}$ & Sigma adjustment for weights and biases into unit $j$
                          in hidden layer $\ell$
\end{tabular}\end{center}
\end{table}


\subsection*{Network architectures}

A network consists of a layer of input units, zero or more hidden
layers of units with some activation function, and a layer of output
units.  Each hidden layer is connected to the preceeding hidden layer
and to the input layer.  The output layer is connected each of the
hidden layers and to the input layer.  Each unit in the hidden and
output layers may have a bias, added to its input from other layers.
Each unit in the input and hidden layers may have an offset, added to
its output.  Any of these sets of parameters may be missing in any
particular network, which has the same effect as their being zero.

The software now also supports connecting a hidden layer to an
earlier hidden layer other than the immediately preceeding one.  Such
non-sequential connections are handled in the obvious way, with 
the required extensions mostly not noted in this presentation.

The interpretation of the output units is determined by the data
model, described below.

When all pairs of connected layers are fully connected, the following 
formulas define the outputs, $v^O_i$, of a network for given values 
of the inputs, $v^I_i$:\beq
  u^{\ell}_j & = & b^{\ell}_j \ +\ \sum_i w^{I,\ell}_{i,j} (v^I_i+t^I_i) 
                   \ +\ \sum_i w^{\ell-1,\ell}_{i,j} (v^{\ell-1}_i+t^{\ell-1}_i)
     \label{func1} \\[3pt]
  v^{\ell}_i & = & a^{\ell}(u^{\ell}_i) \label{func2} \\[5pt]
  v^O_j\!    & = & b^O_i \ +\ \sum_i w^{I,O}_{i,j} (v^I_i+t^I_i) 
             \ +\ \sum_{\ell} \sum_i w^{\ell,O}_{i,j} (v^{\ell}_i+t^{\ell}_i)
\label{func3}\eeq% 
Here, $a^{\ell}$ is the activation function used for layer $\ell$.
The summations are over all units in the appropriate layer.  (The
number of units in each layer is part of the architecture
specification, but these numbers are not given symbols here.)  The
term in the equation for $u^{\ell}_i$ involving layer $\ell\!-\!1$ is
omitted for the first hidden layer; terms involving other pairs of
layers will also be omitted when those connections are absent from the
architecture.

The following activation functions of this form are supported:\vspace{-24pt}
\begin{quotation}\noindent
\begin{tabbing}
{\bf tanh:}\ \ \ \ \ \ \ \= $a(u)\ =\ \tanh(u)$\\[3pt]
{\bf softplus:}\> $a(u)\ =\ \log(1+\exp(u))$\\[3pt]
{\bf softplus0:}\> $a(u)\ =\ \log(1+\exp(u))\ -\ \log(2)$\\[3pt]
{\bf identity:}\> $a(u)\ =\ u$
\end{tabbing}\vspace*{-12pt}
\end{quotation}
Alternatively, a layer, $\ell$, may compute its values, $v^{\ell}_i$
from its summed inputs, $u^{\ell}_i$, in a manner that does not
decompose into computation of $v^{\ell}_i$ from $u^{\ell}_i$
separately for each $i$, as is the case for \textbf{softmax} and 
\textbf{normalization} layers.  The softmax computation is\vspace{-5pt}
\beq
  v^{\ell}_i = \exp(u^{\ell}_i)\,/\,\textstyle \sum\limits_j \exp(u^{\ell}_j)
  \\[-15pt]\nonumber
\eeq
Computation for normalization layers is defined by
\beq
 s^{\ell} & = & \textstyle 
   \sqrt{\,0.01\,+\,\sum\nolimits_j [u^{\ell}_j]^2\,/\,n^{\ell}\,} 
   \label{defs}\\[3pt]
 v^{\ell}_i & = & u^{\ell}_i\,/\,s
\eeq
where $n^{\ell}$ is the number of units in layer $\ell$.  Normalization
may instead be done separately for sub-groups of units.

After the activation function has been applied, the values of units in
a layer may optionally be multiplied by a value or values from an
earlier layer.  The values used from this previous layer will be after
any such multiplication for that layer, and after addition of the
offset (if present) for that unit.  For example, if layer $\ell$ is
fully connected to layer $\ell\!-\!1$ (but not to other layers), uses the
$\tanh$ activation function, and has its values multiplied by
corresponding values in layer $\ell\!-\!2$, then
\beq
  u^{\ell}_j & = & b^{\ell}_j 
                   \ +\ \sum_i w^{\ell-1,\ell}_{i,j} (v^{\ell-1}_i+t^{\ell-1}_i)
  \\[3pt]
  v^{\ell}_i & = & (v^{\ell-2}_i+t^{\ell-2})\,\tanh(u^{\ell}_i)
\eeq

Connections from an input layer to a hidden or output layer may not be
fully connected, but can instead be configured by specifying a set,
$C^{I,\ell}$ of triplets, $(i,j,k)$, indicating that unit $i$ in the
input layer contributes to the input of unit $j$ of the hidden layer,
using the weight indexed by $k$, or similarly by a set $C^{I,O}$ for
the output layer.  The set of weights referenced may be smaller (or
larger) than the number that would be present if each input unit
connects to each hidden or output unit, with an unshared weight.  The
configuration may specify that a weight is shared by more than one
$i$,$j$ pair, and a single $i$,$j$ pair may be connected with more
than one weight.  (The simple case in which some inputs are omitted,
but the layers are otherwise fully connected, can be specified by a
special syntax, and is handled specially computationally.)

Similarly, connections from a hidden layer to the next hidden layer
may be specified by a set of triplets $C^{\ell\!-\!1,\ell}$, and
connections from the last hidden layer to the output layer may be
specified by a set $C^{\ell,O}$, with $\ell$ the index of the last
hidden layer.

The bias connections for a hidden or output layer may also be
configured, by specifying a set, $B^{\ell}$ or $B^O$, of doublets,
$(j,k)$, indicating that the bias indexed by $k$ is used for unit $j$.
A bias may be shared among several units. Some units may have no bias,
or more than one bias.

When the biases and connections to a hidden layer from inputs and the
previous hidden layer are configured in this way, the input to a hidden
unit is computed as follows:
\beq
  u^{\ell}_j & = & 
         \sum_{k\,:\, (j,k)\in B^{\ell}}\!\!\!\!\!\!
                        b^{\ell}_k \ +\!\!\!
         \sum_{(i,k)\,:\, (i,j,k)\in C^{I,\ell}}\!\!\!\!\!\!
                        w^{I,\ell}_k (v^I_i+t^I_i) \ +\!\!\!
         \sum_{(i,k)\,:\, (i,j,k)\in C^{\ell\!-\!1,\ell}}\!\!\!\!\!\!
               w^{\ell-1,\ell}_k (v^{\ell-1}_i+t^{\ell-1}_i)
\label{func1-c}\eeq%
When some of the connections or biases into a hidden layer are
configured in this way, but others are fully-connected, the
appropriate combination of equations~(\ref{func1}) and (\ref{func1-c})
is used.


\subsection*{Data models}\label{app-sec-models}

Networks are normally used to define models for the conditional
distribution of a set of ``target'' values given a set of ``input''
values.  There are three sorts of models, corresponding to three sorts
of targets --- real-valued targets (a ``regression'' model),
binary-valued targets (a ``logistic regression'' model), and ``class''
targets taking on values from a (small) finite set (generalized
logistic regression, or ``softmax'') --- plus survival models, which
are not described here.  For regression and logistic regression
models, the number of target values is equal to the number of network
outputs.  For the softmax model, there is only one target, with the
number of possible values for this target being equal to the number of
network outputs.

The distributions for real-valued targets, $y_j$, in a case with inputs 
$v^I_i$ may be modeled by independent Gaussian distributions 
with means given by the corresponding network outputs, and with
standard deviations given by the hyperparameters $\sigma_{j}$.  
The probability density for a target given the associated inputs and
the network parameters is then\beq
  P(y_j\ |\ \mbox{inputs},\, \mbox{parameters}) & = &
    {1 \over \sqrt{2\pi} \sigma_{j}} 
    \exp \big( - (y_j-v^O_j)^2 \big/ 2\sigma_{j}^2 \big)
\label{regg}\eep

Alternatively, each case, $c$, may have its own set of standard
deviations, $\sigma_{j,c}$, with the corresponding precisions,
$\tau_{j,c} = \sigma_{j,c}^{-2}$ being given Gamma distributions with
means of $\tau_{j}$ and shape parameter $\alpha_2$ (called this for
reasons that will be clear later):\beq
  P(\tau_{j,c}\ |\ \tau_{j}) 
   & = & {(\alpha_2/2\tau_j)^{\alpha_2/2} \over \Gamma(\alpha_2/2)}\,
         \tau_{j,c}^{\alpha_2/2-1}
         \exp \big(-\tau_{j,c} \alpha_2 \big/ 2 \tau_{j} \big)
\eeq%
The previous case corresponds to the degenerate Gamma distribution
with $\alpha_2=\infty$.  Otherwise, integrating out $\tau_{j,c}$ gives a 
$t$-distribution for the target with $\alpha_2$ ``degrees of freedom'':\beq
  P(y_j\ |\ \mbox{inputs},\, \mbox{parameters}) & = &
%    {\Gamma((\alpha_2\!+\!1)/2)\, (\alpha_2/\tau_j)^{\alpha_2/2} \over 
%     \Gamma(\alpha_2/2) \sqrt{\pi}}\,
%     \big[ \alpha_2/\tau_j + (y_j-v^O_j)^2 \big]^{-(\alpha_2+1)/2}\ \ \ \ \ \
%     \\[3pt]
%  & = &
    {\Gamma((\alpha_2\!+\!1)/2) \over \Gamma(\alpha_2/2) 
     \sqrt{\pi\alpha_2}\sigma_j}\,
     \big[ 1 + (y_j-v^O_j)^2\big/\alpha_2^{\ }\sigma_j^2 \big]^{-(\alpha_2+1)/2}
     \ \ \
\label{regt}\eep

The probability that a binary-valued target has the value $1$ is given by \beq
  P(y_j = 1\ |\ \mbox{inputs},\, \mbox{parameters}) & = & 
    \big[ 1 + \exp(-v^O_j) \big]^{-1}
\label{bin}\eep

The probability that a class target, $y$, has the value $j$ is given by\beq
  P(y = j\ |\ \mbox{inputs},\, \mbox{parameters}) & = & 
    \textstyle \exp(v^O_j) \,\big/\, \sum\limits_k \exp(v^O_k)
\label{softmax}\eep


\subsection*{Prior distributions for parameters and hyperparameters}

The prior distributions for the parameters of a network are defined in
terms of hyperparameters.  Conceptually, there is a one hyperparameter
for every parameter, but these lowest-level hyperparameters are not
explicitly represented.  Mid-level hyperparameters control the
distribution of a group of low-level hyperparameters that are all of
one type and all associated with the same source unit.  High-level (or
``common'') hyperparameters control the distribution of the mid-level
hyperparameters, or of the low-level hyperparameters for parameter
types with no mid-level hyperparameters.  The same three-level scheme
is used for the noise level in regression models.

These hyperparameters are represented in terms of ``sigma'' values,
$\sigma$, but their distributions are specified in terms of the
corresponding ``precisions'', $\tau = \sigma^{-2}$, which are given
Gamma distributions.  The top-level mean is given by a ``width''
parameter associated with the parameter type.  The shape parameters of
the Gamma distributions are determined by ``alpha'' values associated
with each type of parameter.  An alpha value of infinity concentrates
the entire distribution on the mean, effectively removing one level
from the hierarchy.

The sigma for a weight may also be multiplied by an ``adjustment'' that
is associated with the destination unit.  This gives the following 
generic scheme:\beq
  P(\tau_w)
   & = & {(\alpha_{w,0}/2\omega_w)^{\alpha_{w,0}/2} 
          \over \Gamma(\alpha_{w,0}/2)}\,
         \tau_w^{\alpha_{w,0}/2-1}
         \exp \big(-\tau_w \alpha_{w,0} \big/ 2 \omega_w\big) \\[3pt]
  P(\tau_{w,i}\ |\ \tau_w)
   & = & {(\alpha_{w,1}/2\tau_w)^{\alpha_{w,1}/2} 
          \over \Gamma(\alpha_{w,1}/2)}\,
         \tau_{w,i}^{\alpha_{w,1}/2-1}
         \exp\big(-\tau_{w,i} \alpha_{w,1} \big/ 2 \tau_w\big) \\[3pt]
  P(\tau_{a,j})
   & = & { (\alpha_a/2)^{\alpha_a/2} \over \Gamma(\alpha_a/2) }\,
         \tau_{a,j}^{\alpha_a/2-1} \exp\big(-\tau_{a,j} \alpha_a \big/ 2\big)
\eeq%
For weights from input units to output units, for example, $\tau_w$
will equal $\tau^{I,O}_w = [\sigma^{I,O}_w]^{-2}$, and similarly for
$\tau_{w,i}$, while $\tau_{a,j}$ will equal $[\sigma^O_{a,i}]^{-2}$.
The top-level precision value, $\omega_w$, is derived from the
``width'' parameter specified for this type of weight. The positive
(possibly infinite) values $\alpha_{w,0}$ and $\alpha_{w,1}$ are
also part of the prior specification for input to output weights,
while $\alpha_a$ is a specification associated with the output units
(note that in this case the ``width'' parameter is fixed at one, as
freedom to set it would be redundant).

Weights for connections between other pairs of layers are given priors
in similar fashion, except that when a pair of layers has configured
connections, rather than being fully connected, the prior
specification for the weights must have infinite $\alpha_{w,1}$, and
the adjustments for the destination layer are ignored (assumed to be
one) --- since neither of these makes sense when the weights are not
associated with a particular source and destination unit.

The distribution for a weight from unit $i$ of one layer to unit $j$ of
another layer may be Gaussian with mean zero and standard deviation given 
by $\sigma_{w,i}\sigma_{a,j} = [\tau_{w,i}\tau_{a,j}]^{-1/2}$. That is:\beq
  P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) & = &
    {1 \over \sqrt{2\pi} \sigma_{w,i}\sigma_{a,j}} 
    \exp \big( - w_{i,j}^2 \big/ 2\sigma_{w,i}^2\sigma_{a,j}^2 \big)
\label{priorwg}\eeq%
Here, $w_{i,j}$ represents, for example, $w^{I,O}_{i,j}$, in which case
$\sigma_{w,i}$ represents $\sigma^{I,O}_{w,i}$ and $\sigma_{a,j}$ represents
$\sigma^O_{a,j}$.  When the weights are for configured connections, $w_{i,j}$
is replaced by $w_k$, $\sigma_{w,i}$ is replaced by $\sigma_w$, and
$\sigma_{a,j}$ is replaced by 1.

Alternatively, each individual weight may have its own ``sigma'', with
the corresponding precision having a Gamma distribution with mean
$\tau_{w,i}\tau_{a,j}$ and shape parameter given by $\alpha_{w,2}$.  The
previous case corresponds to the degenerate distribution with
$\alpha_{w,2} = \infty$.  Otherwise, we can integrate over the individual
precisions and obtain $t$-distributions for each weight:\beq
  P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) & \!=\! &
    {\Gamma((\alpha_{w,2}\!+\!1)/2) \over 
     \Gamma(\alpha_{w,2}/2) \sqrt{\pi\alpha_{w,2}}\, \sigma_{w,i}\sigma_{a,j}}\,
     \big[ 1 + w_{i,j}^2 \big/ \alpha_{w,2}^{\ }\sigma_{w,i}^2\sigma_{a,j}^2 
     \big]^{ -(\alpha_{w,2}+1)/2}\ \ \ \ \ \ \
\label{priorwt}\eeq
When the weights are for a configured set of connections, $w_{i,j}$ is
replaced by $w_k$, and so forth, as above.

The same scheme is used for biases, except that there are in
these cases no mid-level hyperparameters.  We have \beq
  P(\tau_b)
   & = & {(\alpha_{b,0}/2\omega_b)^{\alpha_{b,0}/2} 
          \over \Gamma(\alpha_{b,0}/2)}\,
         \tau_b^{\alpha_{b,0}/2-1}
         \exp \big(-\tau_b \alpha_{b,0} \big/ 2 \omega_b \big) 
\eeq%
where $\tau_b$ might, for example, be $\tau^{O}_b = [\sigma^{O}_b]^{-2}$, etc.

The distribution of the biases is then either\beq
  P(b_i\ |\ \sigma_b,\,\sigma_{a,i}) & = &
    {1 \over \sqrt{2\pi} \sigma_b\sigma_{a,i}} 
    \exp \big( - b_i^2 \big/ 2\sigma_b^2\sigma_{a,i}^2 \big)
\label{priorbg}\eeq%
if $\alpha_{b,1}=\infty$, or if not\beq
  P(b_i\ |\ \sigma_b,\,\sigma_{a,i}) & = &
    {\Gamma((\alpha_{b,1}\!+\!1)/2) \over 
     \Gamma(\alpha_{b,1}/2) \sqrt{\pi\alpha_{b,1}}\, \sigma_b \sigma_{a,i}}
     \big[ 1 + b_i^2 \big/ \alpha_{b,1}^{\ }\sigma_b^2\sigma_{a,i}^2 
     \big]^{-(\alpha_{b,1}+1)/2}
\label{priorbt}\eep

For the offsets added to hidden unit values, there are no mid-level 
hyperparameters, and neither are ``adjustments'' used.  We 
have\vspace{-10pt}\beq
  P(\tau_t)
   & = & {(\alpha_{t,0}/2\omega_t)^{\alpha_{t,0}/2} 
          \over \Gamma(\alpha_{t,0}/2)}\,
         \tau_t^{\alpha_{t,0}/2-1}
         \exp \big(-\tau_t \alpha_{t,0} \big/ 2 \omega_t \big) 
\eeq%
where $\tau_t$ might, for example, be $\tau^{I}_t = [\sigma^{I}_t]^{-2}$, etc.

The distribution of the offsets is then either\beq
  P(y_i\ |\ \sigma_t) & = &
    {1 \over \sqrt{2\pi} \sigma_t} 
    \exp \big( - t_i^2 \big/ 2\sigma_t^2 \big)
\label{priortg}\eeq%
if $\alpha_{t,1}=\infty$, or if not\beq
  P(b_i\ |\ \sigma_t) & = &
    {\Gamma((\alpha_{t,1}\!+\!1)/2) \over 
     \Gamma(\alpha_{t,1}/2) \sqrt{\pi\alpha_{t,1}}\, \sigma_t}
    \big[ 1 + t_i^2 \big/ \alpha_{t,1}^{\ }\sigma_t^2\big]^{-(\alpha_{t,1}+1)/2}
\label{priortt}\eep

The scheme for noise levels in regression models is also similar, with
$\tau_j$, the precision for target $j$, being specified in terms of
an overall precision, $\tau$, as follows:\beq
  P(\tau)
   & = & {(\alpha_{0}/2\omega)^{\alpha_{0}/2} 
          \over \Gamma(\alpha_{0}/2)}\,
         \tau^{\alpha_{0}/2-1}
         \exp \big(-\tau \alpha_{0} \big/ 2 \omega \big) 
\label{noiseprior1}\\[3pt]
  P(\tau_{j}\ |\ \tau)
   & = & {(\alpha_{1}/2\tau)^{\alpha_{1}/2} 
          \over \Gamma(\alpha_{1}/2)}\,
         \tau_{j}^{\alpha_{1}/2-1}
         \exp \big(-\tau_{j} \alpha_{1} \big/ 2 \tau \big)
\label{noiseprior2}\eeq%
where $\omega$, $\alpha_0$, and $\alpha_1$ are parts of the noise
specification.  A third alpha ($\alpha_2$) is needed for the final
specification of the noise in individual cases, as described in the
Section~\ref{app-sec-models}.


\subsection*{Scaling of priors}

The top-level precisions used in the preceding hierarchical priors
(the $\omega$ values) may simply be taken as specified (actually, what
is specified is the corresponding ``width'', $\omega^{-1/2}$).
Alternatively, for connection weights only (not biases and offsets),
the $\omega$ for parameters of one type may be scaled automatically,
based on the number of source units that feed into each destination
unit via connections of this type.  This scaling is designed to
produced sensible results as the number of source units goes to
infinity, while all other specifications remain unchanged.  Scaling is
not allowed for configured connections, since the proper scaling would
depend on the (unknown) way in which the configuration would change
with the number of souce units.

The theory behind this scaling concerns the convergence of sums of
independent random variables to ``stable laws''.  The symmetric stable
laws are characterized by a width parameter and an index, $\alpha$, in
the range (0,2].  If $X_1,\ldots,X_n$ are distributed according to a
symmetric stable law of index $\alpha$, then
$(X_1+\cdots+X_n)/n^{1/\alpha}$ is distributed according to the same
stable law.  The stable law with index 2 is the Gaussian.  The sums of
all random variables with finite variance converge to the Gaussian,
along with some others.  Typically, random variables whose moments are
defined up to but not including $\alpha$ converge to the stable law
with index $\alpha$, for $\alpha<2$.

This leads to the following scaling rules for producing $\omega$ based 
on the specified base precision, $\omega_0$, the number of source units, $n$,
and the relevant $\alpha$ value (see below):\beq
  \omega & = & \left\{\begin{array}{ll}
     \omega_0 n                         & \mbox{for $\alpha=\infty$} \\[2pt]
     \omega_0 n \alpha / (\alpha\!-\!2) & \mbox{for $\alpha>2$} \\[2pt]
     \omega_0 n \log n                  & \mbox{for $\alpha=2$ 
        \ \ (but fudged to $\omega_0 n$ if $n<3$)} \\[2pt]
     \omega_0 n^{2/\alpha}              & \mbox{for $\alpha<2$} 
  \end{array}\right.
\eeq%
Here, $\alpha$ is $\alpha_{w,2}$ if that is finite, and is otherwise
$\alpha_{w,1}$.  The scheme doesn't really work if both $\alpha_{w,1}$
and $\alpha_{w,2}$ are finite.  When $\alpha=2$, the scaling produces
convergence to the Gaussian distribution, but with an unusual scale
factor, as the $t$-distribution with $\alpha=2$ is in the
``non-normal'' domain of attraction of the Gaussian distribution.


\subsection*{Conditional distributions for hyperparameters}

Implementation of Gibbs sampling for hyperparameters requires sampling
from the conditional distribution for one hyperparameter given the
values of the other hyperparameters and of the network parameters.


\subsubsection*{Lowest-level conditional distributions}

The simplest conditional distributions to sample from are those for 
``sigma'' hyperparameters that directly control a set of network
parameters.  This will be the situation for the lowest level
sigmas, as well as for higher level sigmas when the lower level sigmas
are tied exactly to this higher level sigma (i.e.\ when the ``alpha''
shape parameter for their distribution is infinite).  The situation is
analogous for sigma values relating to noise in regression models,
except that the errors in training case are what is modeled, rather
than the network parameters.

In general, we will have some hyperparameter $\tau=\sigma^{-2}$ that
has a Gamma prior, with shape parameter we will call $\alpha$, and
with mean $\omega$ (which may be a higher-level hyperparameter).  The
purpose of $\tau$ is to specify the precisions for the independent
Gaussian distributions of $n$ lower-level quantities, $z_i$.  In this
situation, the conditional distribution for $\tau$ will be given by the
following proportionality:\beq
  P(\tau\ |\ \{z_i\},\,\ldots) & \propto &
    \tau^{\alpha/2-1} \exp(-\tau\alpha/2\omega) \ \cdot\ 
    \prod_i \tau^{1/2} \exp(-\tau z_i^2/2) \label{cond1}\\[3pt]
  & \propto &
    \tau^{(\alpha+n)/2-1} 
    \exp\big({\textstyle-\tau(\alpha/\omega+\sum\limits_i z_i^2)/2}\big)
\eeq%
The first factor in equation~(\ref{cond1}) derives from the prior for $\tau$, 
the remaining factors from the effect of $\tau$ on the probabilities of the 
$z_i$.  The result is a Gamma distribution that can be sampled from by 
standard methods (Devroye 1986).

When the distributions of the $z_i$ are influenced by ``adjustments'',
$\tau_{a,i}$, the above formula is modified as follows:\beq
  P(\tau\ |\ \{z_i\},\,\{\tau_{a,i}\},\,\ldots) 
  & \propto &
    \tau^{(\alpha+n)/2-1} 
    \exp\big({\textstyle-\tau(\alpha/\omega+\sum\limits_i \tau_{a,i}z_i^2)/2}
    \big)
\eeq%
Gibbs sampling for the adjustments themselves is done in similar fashion,
using the weighted sum of squares of parameters influenced by the adjustment,
with the weights in this case being the precisions associated with each 
parameter.


\subsubsection*{Higher-level conditional distributions}

Sampling from the conditional distribution for a sigma hyperparameter
that controls a set of lower-level sigmas is more difficult, but can
be done in the most interesting cases using rejection sampling.

Assume that we wish to sample from the distribution for a precision
hyperparameter $\tau$, which has a higher level Gamma prior specified
by $\alpha_0$ and $\omega$, and which controls the distributions of
lower-level hyperparameters, $\tau_i$, that have independent Gamma
distributions with shape parameter $\alpha_1$ and mean $\tau$.  The
conditional distribution for $\tau$ is then given by the following
proportionality:\beq
  P(\tau\ |\ \{\tau_i\}, \ldots) & \propto &
    \tau^{\alpha_0/2-1} \exp(-\tau\alpha_0/2\omega) \ \cdot\ 
    \prod_i \tau^{-\alpha_1/2} \exp(-\tau_i\alpha_1/2\tau) \\[3pt]
  & \propto &
    \tau^{(\alpha_0-n\alpha_1)/2-1} 
    \exp\Big({\textstyle-\tau\alpha_0/2\omega
           \ -\ (\alpha_1\sum\limits_i \tau_i)\,\big/\,2\tau}\Big)
\eeq%
Defining $\gamma=1/\tau$, we get:\beq
  P(\gamma\ |\ \{\tau_i\}, \ldots) & \propto & 
    \tau^2\,P(\tau\ |\ \{\tau_i\}, \ldots) \\[3pt]
  & \propto &
    \tau^{(\alpha_0-n\alpha_1)/2+1} 
    \exp\Big({\textstyle-\tau\alpha_0/2\omega
           \ -\ (\alpha_1\sum\limits_i \tau_i)\,\big/\,2\tau}\Big) \\[3pt]
  & \propto &
    \gamma^{(n\alpha_1-\alpha_0)/2-1} 
    \exp\Big({\textstyle -\gamma(\alpha_1\sum\limits_i \tau_i)\,\big/\,2}\Big)
    \ \cdot\ \exp\big(\!-\alpha_0/2\omega\gamma\big)\ 
\eeq%
The first part of this has the form of a Gamma distribution for
$\gamma$, provided $n\alpha_1>\alpha_0$; the last factor lies between
zero and one.  If $n\alpha_1>\alpha_0$, we can therefore obtain a
value from the distribution for $\gamma$ by repeatedly sampling from
the Gamma distribution with shape parameter $n\alpha_1\!-\!\alpha_0$
and mean $(n\alpha_1\!-\!\alpha_0)/(\alpha_1\sum\limits_i \tau_i)$
until the value of $\gamma$ generated passes an acceptance test,
which it does with probability $\exp(-\alpha_0/2\omega\gamma)$.  The
probability of rejection will be reasonably low if $\alpha_0$ is
small, which is typical.  It should be possible to develop better
methods if necessary.

In some contexts, the values $\tau_i$ are not explicitly represented,
and must themselves be found by sampling using the method of the
previous section.


\subsection*{Calculation of derivatives}

The hybrid Monte Carlo and other dynamical methods require calculation
of the derivatives of the log of the likelihood of the parameter
values given the data, and of the log of the prior probability of the
parameter values.  This section details how this is done.


\subsubsection*{Derivatives of the log prior probability}

For fixed values of the explicitly-represented hyperparameters, one can
easily obtain the derivatives of the log of the prior probability with 
respect to the network weights and other parameters.  Generically, if
$\alpha_{w,2}=\infty$, we get, from equation~(\ref{priorwg}), that\beq
  {\partial \over \partial w_{i,j}\!\!}\,
     \log P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) & = &
     -\,{w_{i,j} \over \sigma_{w,i}^2\sigma_{a,j}^2}
\eeq%
while otherwise, we get, from equation~(\ref{priorwt}), that\beq
  {\partial \over \partial w_{i,j}\!\!}\,
     \log P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) & = &
     -\, {\alpha_{w,2}+1 \over \alpha_{w,2}^{\ }\sigma_{w,i}^2\sigma_{a,j}^2}\,
    { w_{i,j} \over \big[
      1 + w_{i,j}^2 \big/ \alpha_{w,2}^{\ }\sigma_{w,i}^2\sigma_{a,j}^2
      \big]}
\eep

This is modified in the obvious way when the weights are for
configured connections (indexed by $k$ rather than $i,j$).
Similar formulas for derivatives with respect to the biases are
obtained from equations~(\ref{priorbg}) and~(\ref{priorbt}) and for
derivatives with respect to the offsets from equations~(\ref{priortg})
and~(\ref{priortt}).


\subsubsection*{Derivatives of the log likelihood with respect to 
                output unit values}

The starting point for calculating the derivatives of the log
likelihood with respect to the network parameters is to calculate the
derivative of the log likelihood due to a particular case with respect
to the network outputs.  For the regression model with
$\alpha_2=\infty$, we get from equation~(\ref{regg}) that\beq
  {\partial \over \partial v^O_j\!}\, \log P(y\ |\ v^O_j) & = &
    -\, { y_j-v^O_j \over \sigma_j^2 }
\label{regd}\eeq%
When $\alpha_2$ is finite, we get from equation~(\ref{regt})
that\beq
  {\partial \over \partial v^O_j\!}\, \log P(y\ |\ v^O_j) & = &
    -\, { \alpha_2+1 \over \alpha_2^{\ } \sigma_j^2}\,
        { y_j - v^O_j \over \big[1 + (y_j - v^O_j)^2 \big/
                                 \alpha_2^{\ } \sigma_j^2\big] }
\label{regd2}\eep

For the model of binary targets given by equation~(\ref{bin}), we
get the following, after some manipulation:\beq
  {\partial \over \partial v^O_j\!}\, \log P(y\ |\ v^O_j) & = &
    y_j\, -\, \big[ 1 + \exp(-v^O_j) \big]^{-1}\ 
    \ =\ \ y_j \,-\, P(y_j=1\ |\ v^O_j)\ \ \ \
\label{bind}\eep

For the many-way ``softmax'' classification model of equation~(\ref{softmax}),
we get\beq
  {\partial \over \partial v^O_j\!}\, \log P(y\ |\ \{v^O_k\}) & = &
    \delta(y,j)\, -\, {\exp(v^O_j) \over \sum\limits_k \exp(v^O_k)}
    \ \ =\ \ \delta(y,j)\, -\, P(y=j\ |\ \{v^O_k\})\ \ \ \ \ \
\label{classd}\eeq%
Here, $\delta(y,j)$ is one if $y=j$ and zero otherwise.  

From now on, the log likelihood due to one case, $\log P(y\ |\
\mbox{inputs},\,\mbox{parameters}) = \log P(y\,|\,\mbox{outputs})$,
will be denoted by $L$.

\subsubsection*{Backpropagation to earlier unit values}

Once the derivatives of the log likelihood with respect to the output
unit values are known, the standard backpropagation technique can be
used to find the derivatives with respect to the values of the hidden
and input units.  Using equations~(\ref{func1}), (\ref{func2}),
and~(\ref{func3}), we get the following, which can be evaluated going
backwards from the last hidden layer to the first hidden layer, and
then the inputs (if required):\beq
  {\partial L \over \partial v^{\ell}_{i\ }\!} & = & 
    \sum_j w^{\ell,O}_{i,j} {\partial L \over \partial v^O_j} \ +\
    \sum_j w^{\ell,\ell+1}_{i,j} {\partial L\ \over \partial u^{\ell+1}_j\! }
    \label{bderiv}\\[3pt]
  {\partial L \over \partial u^{\ell}_{i\ }\!} & = & 
   a'^{\ell}\big(u^{\ell}_i\big) {\partial L \over \partial v^{\ell}_i } 
   \label{aderiv}\\[3pt]
  {\partial L \over \partial v^I_{i\ }\!} & = & 
    \sum_j w^{I,O}_{i,j} {\partial L \over \partial v^O_j}\ +\
    \sum_{\ell} \sum_j w^{I,\ell}_{i,j} {\partial L \over \partial u^{\ell}_j }
\eeq%
The second term in the first equation above is omitted for the last
hidden layer; additional terms of this sort will be present when there
are non-sequential connections between hidden layers.  

When the connections from a hidden layer to the next hidden layer are
configured, the first equation above is modified as follows:\beq
  {\partial L \over \partial v^{\ell}_{i\ }\!} & = & 
    \sum_j w^{\ell,O}_{i,j} {\partial L \over \partial v^O_j} \ +\!\!\!
   \sum_{(j,k)\,:\, (i,j,k)\in C^{\ell,\ell\!+\!1}}\!\!\!\!\!\!    
     w^{\ell,\ell+1}_{i,j} {\partial L\ \over \partial u^{\ell+1}_j\! }
\eeq

Similarly, when all connections from the inputs to hidden layers are
configured, the last equation above is modified as follows:\beq
  {\partial L \over \partial v^I_{i\ }\!} & = & 
    \sum_j w^{I,O}_{i,j} {\partial L \over \partial v^O_j}\ +\
    \sum_{\ell} 
         \sum_{(j,k)\,:\, (i,j,k)\in C^{I,\ell}}\!\!\!\!\!\!
             w^{I,\ell}_k {\partial L \over \partial u^{\ell}_j }
\eeq%
The obvious modifications to the above are made when some of the 
hidden layers are fully-connected to the inputs and some have
configured connections to the inputs.

In equation~(\ref{aderiv}), $a'^{\ell}(u^{\ell}_i)$ is the derivative of
the activation function, evaluated at $u^{\ell}_i$.  For computational
reasons, it is convenient to express this derivative in terms of
$v^{\ell}_i$, which is possible since all the activation functions
used are strictly monotonic.  For the $\tanh$ activation function, the
derivative of $a$ is $1 - \big[v^{\ell}_i\big]^2\!$.  For the softplus
activation function, it is $1 - \exp(-v^{\ell}_i)$, and for softplus0,
it is $1 - \exp(-v^{\ell}_i-\log(2)))$.

For a softmax layer, equation~(\ref{aderiv}) is replaced by
\beq
 t^{\ell} & = & 
   \sum_j {\partial L \over \partial v^{\ell}_{j\ }\!}\,v^{\ell}_j
   \\[3pt]
 {\partial L \over \partial u^{\ell}_{i\ }\!} & = & 
   v^{\ell}_i \Big( {\partial L \over \partial v^{\ell}_{j\ }\!}
     \ -\ t^{\ell} \Big)
\eeq 
where $s^{\ell}$ is defined by equation~(\ref{defs}).  This is modified 
in the obvious way when normalization is done separately for sub-groups.

For a normalization layer, equation~(\ref{aderiv}) is replaced by
\beq
 t^{\ell} & = & 
   \sum_j {\partial L \over \partial v^{\ell}_{j\ }\!}\,v^{\ell}_j\,/\,n^{\ell}
   \\[3pt]
 {\partial L \over \partial u^{\ell}_{i\ }\!} & = & 
   {1 \over s^{\ell}} \Big( {\partial L \over \partial v^{\ell}_{j\ }\!}
     \ -\ v^{\ell}_k t^{\ell} \Big)
\eeq 
where $s^{\ell}$ is defined by equation~(\ref{defs}).  This is modified 
in the obvious way when normalization is done separately for sub-groups.

When values for layer $\ell$ are multiplied by corresponding values in some 
earlier layer, say $\ell\!-\!2$, equation~(\ref{aderiv}) for layer $\ell$ 
must be modified as follows:
\beq
  {\partial L \over \partial u^{\ell}_{i\ }\!} & = & 
   (v^{\ell-2}_i+t^{\ell-2}_i)\,a'^{\ell}\big(u^{\ell}_i\big)
    {\partial L \over \partial v^{\ell}_i } 
\eeq
and equation~(\ref{bderiv}) for layer $\ell\!-\!2$ must be modified to
include the contribution due to the effect of layer $\ell\!-\!2$ on
the outputs of layer $\ell$:
\beq
{\partial L \over \partial v^{\ell-2}_{i\ }\!} & = &
  \sum_j w^{\ell-2,O}_{i,j} {\partial L \over \partial v^O_j} \ +\
  \sum_j w^{\ell-2,\ell-1}_{i,j} {\partial L\ \over \partial u^{\ell-1}_j\!}
   \ +\ a^{\ell}\big(u^{\ell}_i\big) {\partial L\ \over \partial v^{\ell}_i\!}
\eeq

\subsubsection*{Derivatives of the log likelihood with respect to parameters}

The derivatives of $L$ with respect to the network parameters (with
any explicitly represented noise sigmas fixed) are obtained using the
derivatives with respect to unit values and unit inputs that were found in 
the previous section, as follows:\beq
  {\partial L \over \partial b^O_{i\ }\!} & = & 
    {\partial L \over \partial v^O_i} \\[5pt]
  {\partial L \over \partial b^{\ell}_{i\ }\!} & = & 
    {\partial L \over \partial u^{\ell}_i} \\[5pt]
  {\partial L \over \partial t^{\ell}_{i\ }\!} & = & 
    {\partial L \over \partial v^{\ell}_i} \\[5pt]
  {\partial L \over \partial t^I_{i\ }\!} & = & 
    {\partial L \over \partial v^I_i} \\[5pt]
  {\partial L\ \over \partial w^{\ell,O}_{i,j}\!} & = &
    {\partial L \over \partial v^O_{j\ }\!}\ (v^{\ell}_i+t^{\ell}_i) \\[5pt]
  {\partial L\ \over \partial w^{\ell-1,\ell}_{i,j}\!\!} & = &
    {\partial L \over \partial u^{\ell}_{j\ }\!}\ (v^{\ell-1}_i+t^{\ell-1}_i)
    \\[5pt]
  {\partial L\ \over \partial w^{I,\ell}_{i,j}\!\!} & = &
    {\partial L \over \partial u^{\ell}_{j\ }\!}\ (v^I_i+t^I_i) \\[5pt]
  {\partial L\ \over \partial w^{I,O}_{i,j}\!\!} & = &
    {\partial L \over \partial v^O_{j\ }\!}\ (v^I_i+t^I_i) 
\eeq%
The derivatives found will then be summed across training cases, and 
added to the derivatives with respect to the log prior probability, to
give the derivatives with respect to the log posterior probability,
which controls the dynamics for HMC or gradient descent.


\subsection*{Heuristic choice of stepsizes}\label{app-sec-heuristic}

Stepsizes for Metropolis updates and dynamical trajectory computations
are heuristically chosen based on the values of the training inputs
and the current values of the hyperparameters.  These stepsize choices
are made on the assumption that the system is near equilibrium, moving
about in a Gaussian hump.  If the axes of this hump were aligned with
the coordinate axes, the optimal stepsize along each axis would be in
the vicinity of the standard deviation along that axis.  Since the
axes of the bowl may not be aligned with the coordinate axes, the
actual stepsizes may have to be less than this.  On the other hand,
the estimates used are in some respects conservative.  Adjustments to
account for these factors are left to the user.

Estimates of the posterior standard deviations along the axes are
based on estimates of the second derivatives of the log posterior
probability along the axes.  These second derivatives are estimated
using estimates of the second derivatives of the log likelihood with
respect to the values of units in the network.

For real-valued targets, with $\alpha_2=\infty$, we get the following,
using equation~(\ref{regd}):\beq
  - {\partial^2 L \over \partial (v^O_j)^2} & = & {1 \over \sigma_j^2}
\eeq%
while for finite $\alpha_2$, we get from equation~(\ref{regd2}) that\beq
  - {\partial^2 L \over \partial (v^O_j)^2} & = &
    {\alpha_2 + 1 \over \alpha_2^{\ } \sigma_j^2} \bigg[
    \Big( 1 + {(v^O_j)^2 \over \alpha_2^{\ }\sigma_j^2} \Big)^{-1}
    \, +\
    {2(v^O_j)^2 \over \alpha_2^{\ }\sigma_j^2} 
    \Big( 1 + {(v^O_j)^2 \over \alpha_2^{\ }\sigma_j^2} \Big)^{-2}
   \bigg]
\eeq%
This is estimated by its maximum value, which occurs at $v^O_j=0$:\beq
  - {\partial^2 L \over \partial (v^O_j)^2} & \approx & 
    {\alpha_2 + 1 \over \alpha_2^{\ } \sigma_j^2} 
\label{maxhest}\eep

For binary-valued targets, equation~(\ref{bind}) gives\beq
  - {\partial^2 L \over \partial (v^O_j)^2} 
     \ \ =\ \ { 1 \over [1+\exp(v^O_j)] [1+\exp(-v^O_j)]}
     \ \ \approx\ \ {1 \over 4}
\eeq%
Again, the estimate is based on the maximum possible value, which occurs
when $v^O_j=0$.

We get a similar estimate for a class target, using equation~(\ref{classd}):\beq
  - {\partial^2 L \over \partial (v^O_j)^2} 
     \ \ =\ \ {\exp(v^O_j) \over \textstyle \sum\limits_k \exp(v^O_k)}
              \left[1 - {\exp(v^O_j) \over \textstyle \sum\limits_k \exp(v^O_k)}
              \right]
     \ \ \approx \ \ {1 \over 4}
\eep

These estimates for the second derivatives of $L$ with respect to the
outputs are propagated backward to give estimates for the second
derivatives of $L$ with respect to the values of hidden and input
units.  

When doing this backward propagation, we need an estimate of the
second derivative of $L$ with respect to the summed input to a
hidden unit, given its second derivative with respect to the unit's
output.  Letting the hidden unit output be $v = a(u)$, we have\beq
  {d^2L \over du^2}
   \ = \ {d \over du} \left[ {dv \over du}\, {dL \over dv} \right] 
   \ = \ a''(u) {dL \over dv} + a'(u)^2 {d^2L \over dv^2}
   \ \approx \ a'(u)^2 {d^2L \over dv^2} 
   \ \approx \ \max[a'(u)^2]\, {d^2L \over dv^2}\ \ \
   \label{approx2nd}
\eeq%
The first approximation assumes that since the first term may be
either positive or negative, its effects will (optimistically) cancel
when averaged over the training set.  Since $u$ is not known, the
second approximation above takes the maximum with respect to $u$.  For
the currently-used unit-by-unit activation functions --- $\tanh$,
softplus, softplus0, and identity --- $\max[a'(u)^2] = 1$, so nothing
need actually be done for this.  For softmax layers, the partial
derivative of a unit's output with respect to its input is no more
than $1/4$.  For normalization layers, it is no more than $1/s^{\ell}$,
where $s^{\ell}$ is defined by equation~(\ref{defs}), so an estimate of
$[1/s^{\ell}]^2 = 1/(0.01\,+\,\sum\nolimits_i [u^{\ell}_i]^2\,/\,n^{\ell})$ 
is needed.  This requires an estimate for a typical value of
$[u^{\ell}_i]^2$, which is discussed below.

When units in this layer are multiplied by unit value(s) of an earlier
layer, the estimate of equation~(\ref{approx2nd}) is multiplied an
estimate of the typical squared value of units in that earlier layer.

Note that this backward propagation ignores any interactions between
multiple connections from a unit.

Since the stepsizes chosen are not allowed to depend on the actual
values of the network parameters, the magnitude of each weight is
taken to be equal to the corresponding sigma hyperparameter,
multiplied by the destination unit adjustment, if present.  This gives
the following generic estimate, when layers are fully connected:\beq
  {\partial^2 L \over \partial (v^S_i)^2} & \approx &
     \sum_D\, \sum_j\, (\sigma^{S,D}_{w,i}\, \sigma^D_{a,j})^2\, 
     {\partial^2 L \over (u^D_j)^2}
  \label{Lv2nd}
\eeq%
Here, $S$ is the source layer, $D$ goes through the various layers
receiving connections from $S$, $\sigma^{S,D}_{w,i}$ is the
hyperparameter controlling weights to layer $D$ out of unit $i$ in
$S$, and $\sigma^D_{a,j}$ is the sigma adjustment for unit $j$ in $D$.
For the output layer, $u^O_j$ is the same as $v^O_j$.
When connections are configured, the formula is
\beq
  {\partial^2 L \over \partial (v^S_i)^2} & \approx &
     \sum_D\, \sum_{(j,k)\,:\,(i,j,k)\in C^{S,D}}\!\!\!\!
       (\sigma^{S,D}_w)^2\, {\partial^2 L \over (u^D_j)^2}
  \label{Lv2ndc}
\eep
If $v^S_i$ is used to multiply unit $j$ in a later layer, $M$,
the following term must be added to equation~(\ref{Lv2nd}) 
or~(\ref{Lv2ndc}):
\beq
  (a(u^M_j))^2\,{\partial^2 L \over \partial (v^M_j)^2}
\eeq
There may be more than one such term, if $v^S_i$ is used to multiply more 
than one unit.  Both factors above must be estimated, the second as
described here, and the first as described below.
     
The second derivative of $L$ with respect to a weight, $w^{S,D}_{i,j}$,
can be expressed as follows:\beq
  {\partial^2 L \over \partial (w^{S,D}_{i,j})^2} & = &
    (v^S_i)^2\,{\partial^2 L \over \partial (u^D_j)^2}
\eeq%
To estimate this, an estimate of $(v^S_i)^2$ is needed.

When the weight is on a connection from an input unit, $v^S_i = v^I_i$
is the $i$th input for this training case, which is known.  The sum of
$(v^I_i)^2$ for all training cases is computed once, for each $i$, and
then used for stepsize heuristics thereafter.  From this sum, the
mean is also computed, and used as the ``typical'' squared value of
that input unit.

Estimates of ``typical'' squared values for hidden units are made by
simulating a forward pass, in which actual parameter values are not
used, but instead parameters are assumed to be typical, given the
current hyperparameters.  Just one simulation is done for each update
needing stepsizes, not one for every training case --- the typical
squared values are taken to be the same for each training case,
approximating (roughly) the mean over training cases.

The typical squared value for a hidden unit with the identity
activation function is found from the sum of the previously-estimated
typical squared values of the units connecting to this unit (one for a
bias connection), with the prior variance of offsets added (if
present), multiplied by the prior variance of the weight (or bias) on
that connection, as given by the controlling hyperparameter.  (For
parameters with t distributions, the variance is capped at what it
would be if the degrees of freedom were three.)

For a layer of tanh hidden units, the typical squared value for the
unit's input found in this way is reduced to one if it exceeds one,
since one is the maximum squared value of tanh.  For the softplus
activation function, if the typical squared value of the unit's input
is less than $\log(2)^2$, the value is increased to $\log(2)^2$, which
is the value when the inputs are zero. For units with the softplus0
activation function, the typical squared input value is used
unchanged, as for the identity activation function.  For softmax
layers, units are taken to have a typical squared value for their
output of one (the maximum possible).  For normalization layers, units
are taken to have a typical squared value for their output equal to
the number of units in their group (also the maximum possible).  

If units in this layer are multiplied by value(s) of units in an
earlier layer, the typical squared value is multiplied by the typical
squared value for this earlier layer.

The typical squared value for the input to a unit, $[u^{\ell}_i]^2$,
found as above, is also used for estimating $d^2L/du^2$ for a
normalization layer, as discussed earlier.

Second derivatives with respect to biases are simply equal to the
second derivatives with respect to the associated summed input to the
hidden or output units.  Second derivatives with respect to offsets
are equal to the second derivatives with respect to the associated
input unit, or with respect to the output of the associated hidden
unit.

These heuristic estimates for the second derivatives of $L$ due to
each training case with respect to the various network parameters are
summed for all cases in the training set.  (No actual summation is
needed, however, only a multiplication, since the typical squared
values used are the same for all training cases.)  To these estimates
are added estimates of the second derivatives of the log prior
probability with respect to each parameter, giving estimates of the
second derivatives of the log posterior.

For the second derivative of the log prior with respect to weight
$w_{i,j}$, we have\beq
  - {\partial^2 \over \partial w_{i,j}^2} 
      \log P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) 
    & = & {1 \over \sigma_{w,i}^2\sigma_{a,j}^2}
\eeq%
if $\alpha_2$ is infinite, while for finite $\alpha_2$, we use an
estimate analogous to equation~(\ref{maxhest}):\beq
 - {\partial^2 \over \partial w_{i,j}^2} 
      \log P(w_{i,j}\ |\ \sigma_{w,i},\,\sigma_{a,j}) 
   & \approx & {\alpha_2 + 1 \over \alpha_2^{\ } \sigma_{w,i}^2 \sigma_{a,j}^2} 
\eeq%
Biases and offsets are handled similarly, as are weights for 
configured connections.

Finally, the stepsize used for a parameter (before the adjustment
factor is applied) is the reciprocal of the square root of minus the
estimated second derivative of the log posterior with respect to that
parameter.


\subsection*{Rejection sampling from the prior}\label{app-rej}

In addition to the Monte Carlo implementations based on Markov chain
sampling, a simple Monte Carlo procedure using rejection sampling has
also been implemented.  This procedure is very inefficient; it is
intended for use only as a means of checking the correctness of the
Markov chain implementations.

The rejection sampling procedure is based on the idea of generating
networks from the prior, and then accepting some of these networks
with a probability proportional to the likelihood given the training
data of the generated parameter and hyperparameter values, thereby
producing a sample from the posterior.  For data models with discrete
targets, this idea can be implemented directly, as the likelihood is
the probability of the targets in the training set, which can be no
more than one.  For regression models, the likelihood is the
probability density of the targets, which can be greater than one,
making its direct use as an acceptance probability invalid.  If the
noise levels for the targets are fixed, however, the likelihood is
bounded, and can be used as the acceptance probability after
rescaling.  For a Gaussian noise model (equation~(\ref{regg})), this
is accomplished by simply ignoring the factors of
$1\,/\,\sqrt{2\pi}\sigma_j$ in the likelihood; the analogous procedure
can be used for noise from a $t$-distribution (equation~(\ref{regt})).

When the noise levels are variable hyperparameters, a slightly more
elaborate procedure must be used, in which the noise levels are not
generated from the prior, but rather from the prior multiplied by a
bias factor that gives more weight to higher precisions (lower noise).
This bias factor is chosen so that when it is cancelled by a
corresponding modification to the acceptance probability, these
probabilities end up being no greater than one.

Specifically, the overall noise precision, $\tau$, and the noise
precisions for individual targets, the $\tau_j$, are sampled from
Gamma distributions obtained by modifying the priors of 
equations~(\ref{noiseprior1}) and~(\ref{noiseprior2}) as follows:\beq
\begin{array}{rcccl}
  f(\tau) &\propto&\tau^{nm/2}\, P(\tau) &\propto&
    \tau^{(\alpha_0+nm)/2-1}\, \exp \big(-\tau \alpha_{0} \big/ 2 \omega \big) 
  \\[3pt]
  f(\tau_j\ |\ \tau) &\propto& \tau_j^{n/2}\, P(\tau_j\ |\ \tau) &\propto&
    \tau^{-(\alpha_1+n)/2}\,
    \tau_j^{(\alpha_1+n)/2-1}\,
    \exp \big(-\tau_{j} \alpha_{1} \big/ 2 \tau \big)
\end{array}
\eeq% 
Here, $n$ is the number of training cases and $m$ is the number of
targets.  The resulting joint sampling density is\vspace{-4pt}\beq
  f(\tau,\,\{\tau_j\}) \ \ =\ \ f(\tau)\,\prod_{j=1}^m f(\tau_j\ |\ \tau)
   \ \ \propto\ \ P(\tau,\,\{\tau_j\})\,\prod_{j=1}^m \tau_j^{n/2}
\eeq%
Since this sampling density is biased in relation to the prior by the
factor $\prod\limits_{j=1}^m \tau_j^{n/2}$, when constructing the
acceptance probability we must multiply the likelihood by the
inverse of this factor, $\prod\limits_{j=1}^m \tau_j^{-n/2} =
\prod\limits_{c=1}^n \prod\limits_{j=1}^m \sigma_j$.  This cancels the
factors of $1/\sigma_j$ in the target probabilities of
equations~(\ref{regg}) and~(\ref{regt}), leaving an acceptance probability
which is bounded, and can be adjusted to be no more than one by ignoring
the remaining constant factors.

\end{document}
